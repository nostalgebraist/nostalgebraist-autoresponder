{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "name": "train_selector",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oksd9Gl8pbXY",
        "colab_type": "text"
      },
      "source": [
        "Train the selector model on Google Colab\n",
        "\n",
        "Similar assumptions about your environment to those in `generator.ipynb`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Atc2NJhG9FRG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZH7MQBnZ5rm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install transformers==2.10.0\n",
        "\n",
        "!pip install --upgrade simpletransformers\n",
        "\n",
        "\n",
        "!pip install --upgrade scikit-learn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUxbHNXjakJH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MfdQ7rsgZy90",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np, pandas as pd\n",
        "import pickle\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2AG8ghwaR9P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "%cd \"/content/drive/My Drive/gpt-2\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLkif9onZy-A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function\n",
        "\n",
        "import os\n",
        "import math\n",
        "import json\n",
        "import random\n",
        "import warnings\n",
        "\n",
        "from multiprocessing import cpu_count\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "from scipy.stats import pearsonr, mode\n",
        "from sklearn.metrics import mean_squared_error, matthews_corrcoef, confusion_matrix, label_ranking_average_precision_score\n",
        "from tensorboardX import SummaryWriter\n",
        "from tqdm.auto import trange, tqdm\n",
        "\n",
        "from torch.utils.data.distributed import DistributedSampler\n",
        "from torch.utils.data import (\n",
        "    DataLoader,\n",
        "    RandomSampler,\n",
        "    SequentialSampler,\n",
        "    TensorDataset\n",
        ")\n",
        "\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup, get_constant_schedule\n",
        "from transformers import (\n",
        "    WEIGHTS_NAME,\n",
        "    BertConfig, BertTokenizer,\n",
        "    XLNetConfig, XLNetTokenizer,\n",
        "    XLMConfig, XLMTokenizer,\n",
        "    RobertaConfig, RobertaTokenizer,\n",
        "    DistilBertConfig, DistilBertTokenizer,\n",
        "    AlbertConfig, AlbertTokenizer,\n",
        "    CamembertConfig, CamembertTokenizer\n",
        ")\n",
        "\n",
        "from simpletransformers.classification.classification_utils import (\n",
        "    InputExample,\n",
        "    convert_examples_to_features\n",
        ")\n",
        "\n",
        "from simpletransformers.classification.transformer_models.bert_model import BertForSequenceClassification\n",
        "from simpletransformers.classification.transformer_models.roberta_model import RobertaForSequenceClassification\n",
        "from simpletransformers.classification.transformer_models.xlm_model import XLMForSequenceClassification\n",
        "from simpletransformers.classification.transformer_models.xlnet_model import XLNetForSequenceClassification\n",
        "from simpletransformers.classification.transformer_models.distilbert_model import DistilBertForSequenceClassification\n",
        "from simpletransformers.classification.transformer_models.albert_model import AlbertForSequenceClassification\n",
        "from simpletransformers.classification.transformer_models.camembert_model import CamembertForSequenceClassification\n",
        "\n",
        "from simpletransformers.classification import ClassificationModel, MultiLabelClassificationModel\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "BERT_CONFIG_DEFAULT = {\"model_type\": \"roberta\", \n",
        "                       \"model_name\": \"roberta-base\",\n",
        "                       \"args\": {'reprocess_input_data': True, \"fp16\": False, \n",
        "                                'train_batch_size': 16, 'eval_batch_size': 16,\n",
        "                                'gradient_accumulation_steps': 1,\n",
        "                                'learning_rate': 1e-5, \n",
        "                                'max_seq_length': 256,\n",
        "                                'sliding_window': False,\n",
        "                                'num_train_epochs': 7,\n",
        "                                'warmup_steps': 0,\n",
        "                                'warmup_ratio': 0.1,\n",
        "                                'weight_decay': 0.1,#0.05,\n",
        "                                'logging_steps': 0,\n",
        "                                'max_grad_norm': 10000.,\n",
        "                                'adam_epsilon': 1e-6,\n",
        "                                'silent': False,\n",
        "                                'overwrite_output_dir': True},\n",
        "                       \"kwargs\": {\"use_cuda\": True, \n",
        "                                  \"num_labels\": 1}}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFqpg9OTaNpD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BERT_CONFIG_EXP = {\"model_type\": \"roberta\", \n",
        "                       \"model_name\": \"roberta-large\",\n",
        "                       \"args\": {'reprocess_input_data': True, \"fp16\": False, \n",
        "                                'train_batch_size': 8, 'eval_batch_size': 8,\n",
        "                                'gradient_accumulation_steps': 2,\n",
        "                                'learning_rate': 1e-5, \n",
        "                                'max_seq_length': 256,\n",
        "                                'sliding_window': False,\n",
        "                                'num_train_epochs': 4,\n",
        "                                'warmup_steps': 0,\n",
        "                                'warmup_ratio': 0.06,\n",
        "                                'weight_decay': 0.025,\n",
        "                                'logging_steps': 0,#51,\n",
        "                                'max_grad_norm': 10000.,\n",
        "                                'adam_epsilon': 1e-6,\n",
        "                                'silent': False,\n",
        "                                'overwrite_output_dir': True,\n",
        "                                'evaluate_during_training': False,\n",
        "                                'use_early_stopping': False,\n",
        "                                'save_model_every_epoch': False,\n",
        "                                'save_optimizer_and_scheduler': False,\n",
        "                                'save_steps': 0,\n",
        "                                },\n",
        "                       \"kwargs\": {\"use_cuda\": True, \n",
        "                                  \"num_labels\": 1}}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLlh803RZy-D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from copy import deepcopy\n",
        "from datetime import datetime\n",
        "\n",
        "def make_bert(output_dir: str, bert_config: dict=BERT_CONFIG_DEFAULT, add_timestamp=False, regression=True, overrides: dict=None):\n",
        "    bert_config_ = deepcopy(bert_config)\n",
        "\n",
        "    output_dir_ = output_dir\n",
        "    if add_timestamp:\n",
        "      output_dir_ += \"_\" + datetime.now().strftime(\"%H-%M-%S\")\n",
        "    bert_config_[\"args\"][\"output_dir\"] = output_dir_\n",
        "    bert_config_[\"args\"][\"best_model_dir\"] = output_dir_ + \"/best_model\"\n",
        "\n",
        "    if regression or bert_config['args'].get('multi_label'):\n",
        "      bert_config_[\"kwargs\"][\"num_labels\"] = 1\n",
        "    else:\n",
        "      bert_config_[\"kwargs\"][\"num_labels\"] = 2\n",
        "\n",
        "    if overrides is not None:\n",
        "      for k, v in overrides.items():\n",
        "        bert_config_[\"args\"][k] = v\n",
        "    \n",
        "    if regression:\n",
        "      constructor = RegressionMode\n",
        "    elif bert_config['args'].get('multi_label'):\n",
        "      constructor = MultiLabelClassificationModel\n",
        "      print('using MultiLabelClassificationModel')\n",
        "    else:\n",
        "      constructor = ClassificationModel\n",
        "    bert = constructor(model_type=bert_config_[\"model_type\"], \n",
        "                            model_name=bert_config_[\"model_name\"],\n",
        "                            args=bert_config_[\"args\"], \n",
        "                            **bert_config_[\"kwargs\"])\n",
        "    return bert"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZEeZaWJZy-N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_path = \"reward/reward.pkl.gz\"\n",
        "with open(data_path, \"rb\") as f:\n",
        "    ids_to_reward_data = pickle.load(f)[\"ids_to_reward_data\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xvmlf8epZy-Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "def inverse_format_post_for_api(post):\n",
        "    if post.startswith(\"<p>\"):\n",
        "        post = post[len(\"<p>\"):]\n",
        "    if post.endswith(\"</p>\"):\n",
        "        post = post[:-len(\"</p>\")]\n",
        "    # post = post.lstrip(\"<p>\").rstrip(\"</p>\")\n",
        "    post = re.sub(r\"</p><p>\", \"\\n\", post)\n",
        "    post = re.sub(r\"<br>\", \"\\n\", post)\n",
        "    return post\n",
        "\n",
        "def make_train_data(ids_to_reward_data, continuation_only=True):\n",
        "    train_data = []\n",
        "    for k, v in ids_to_reward_data.items():\n",
        "      if continuation_only:\n",
        "        train_data.append([k, v[\"continuation\"], v[\"note_count\"]])\n",
        "      else:\n",
        "        train_data.append([k, \" \".join(v[\"prompt\"].split(\" \")[-64:]) + v[\"continuation\"], v[\"note_count\"]])\n",
        "        \n",
        "    train_data = pd.DataFrame(train_data, columns=[\"id\", \"text\", \"note_count\"])\n",
        "\n",
        "    train_data.text = train_data.text.apply(inverse_format_post_for_api)\n",
        "\n",
        "    return train_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3toM2H8MZy-T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = make_train_data(ids_to_reward_data, continuation_only=True)\n",
        "train_data.note_count.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBAxseJ9c8JR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "temporally_ordered_train_data = train_data.sort_values(by=\"id\").reset_index()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWpP0ocqlngH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def non_overlapping_ma(array, width=31):\n",
        "  return pd.Series([np.average(array[ix:ix+width], )\n",
        "   for ix in range(0, len(array), width)])\n",
        "\n",
        "window_width = 140\n",
        "window_halfw = window_width//2\n",
        "\n",
        "skip_n_most_recent = 40\n",
        "\n",
        "allow_partial_windows = False\n",
        "window_frac_left = 0.8 # None\n",
        "\n",
        "rolling_quantiles = {}\n",
        "rolling_advantages = {}\n",
        "\n",
        "if window_frac_left is not None:\n",
        "  window_shift_left = -1*int(window_frac_left*window_width)\n",
        "  window_shift_right = window_width + window_shift_left\n",
        "else:\n",
        "  window_shift_left = -window_halfw\n",
        "  window_shift_right = window_halfw\n",
        "\n",
        "last_ix_allowed = len(temporally_ordered_train_data) - skip_n_most_recent\n",
        "\n",
        "if allow_partial_windows:\n",
        "  ixs = temporally_ordered_train_data.index[:last_ix_allowed]\n",
        "else:\n",
        "  ixs = temporally_ordered_train_data.index[(0-window_shift_left):(last_ix_allowed-window_shift_right)]\n",
        "\n",
        "print(f\"using ({ixs.min()} to {ixs.max()}) of (0 to {len(temporally_ordered_train_data)-1})\")\n",
        "\n",
        "for ix in ixs:\n",
        "  point = temporally_ordered_train_data.loc[ix, 'note_count']\n",
        "  window = temporally_ordered_train_data.loc[ix+window_shift_left:ix+window_shift_right, 'note_count']\n",
        "  rolling_quantiles[ix] = (point>=window).mean()\n",
        "  rolling_advantages[ix] = (point-window).mean()\n",
        "\n",
        "rolling_quantiles = pd.Series(rolling_quantiles)\n",
        "rolling_advantages = pd.Series(rolling_advantages)\n",
        "\n",
        "non_overlapping_ma(rolling_quantiles, width=21).plot(lw=1, ls='--', marker='.', markersize=5, figsize=(10, 6));"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJKiYsVHZy-f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "use_mov_avg = True\n",
        "notes_key = \"rolling_quantile\" if use_mov_avg else \"note_count\"\n",
        "\n",
        "if use_mov_avg:\n",
        "  train_data_ = temporally_ordered_train_data.loc[rolling_quantiles.index]\n",
        "  train_data_[\"rolling_quantile\"] = rolling_quantiles\n",
        "  train_data_[\"rolling_advantage\"] = rolling_advantages\n",
        "else:\n",
        "  train_data_ = temporally_ordered_train_data\n",
        "\n",
        "regression = False\n",
        "drop_midrange = True\n",
        "smaller_midrange_dropped = False\n",
        "\n",
        "reg_log = False\n",
        "reg_cutoff = 30\n",
        "\n",
        "continuation_only = True\n",
        "\n",
        "if drop_midrange and not use_mov_avg:\n",
        "  train_data_[\"target\"] = (train_data_[notes_key]>=4).astype(int)\n",
        "  train_data_ = train_data_[(train_data_[notes_key] <= 1) | (train_data_[notes_key] >=4)]\n",
        "  stratify = train_data_[\"target\"]\n",
        "elif drop_midrange and use_mov_avg:\n",
        "  if smaller_midrange_dropped:\n",
        "    MIDRANGE_BOTTOM = np.percentile(train_data_[notes_key], 30)\n",
        "    MIDRANGE_TOP = np.percentile(train_data_[notes_key], 70)\n",
        "  else:\n",
        "    MIDRANGE_BOTTOM = np.percentile(train_data_[notes_key], 24)\n",
        "    MIDRANGE_TOP = np.percentile(train_data_[notes_key], 76)\n",
        "\n",
        "  train_data_[\"target\"] = (train_data_[notes_key] >= MIDRANGE_TOP).astype(int)\n",
        "  train_data_ = train_data_[(train_data_[notes_key] <= MIDRANGE_BOTTOM) | (train_data_[notes_key] >= MIDRANGE_TOP)]\n",
        "  stratify = train_data_[\"target\"]\n",
        "else:\n",
        "# split at middle\n",
        "  train_data_[\"target\"] = (train_data_[notes_key] > 2).astype(int)\n",
        "  train_data_ = train_data_\n",
        "  stratify = train_data_[\"target\"]\n",
        "\n",
        "\n",
        "model_inputs = train_data_[[\"text\", \"target\"]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IhSjogLuNThF",
        "colab": {}
      },
      "source": [
        "model_inputs.target.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BHHdQDcpZy-1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def baserate_loss(target):\n",
        "  baserate = np.mean(target)\n",
        "\n",
        "  return -1 * (baserate*np.log(baserate) + (1-baserate)*np.log(1-baserate))\n",
        "\n",
        "def baserate_loss_regression(target, ref=None,):\n",
        "  if ref is not None:\n",
        "    baserate = np.mean(ref)\n",
        "  else:\n",
        "    baserate = np.mean(target)\n",
        "\n",
        "  return np.mean((target-baserate)**2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-zV29Heb9_S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def hack_to_avoid_masking(text, tokenizer, max_len=768):\n",
        "  # this was a bad idea, don't use it\n",
        "  tokens = tokenizer.tokenize(text)\n",
        "  npad = max_len - len(tokens)\n",
        "  pads = \" \".join([tokenizer.pad_token for _ in range(npad)])\n",
        "\n",
        "  padded = text + \" \" + pads\n",
        "  return padded"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FqRV1JSWreOf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.base import BaseEstimator, RegressorMixin\n",
        "from sklearn.model_selection import cross_val_predict, cross_validate\n",
        "from sklearn.compose import TransformedTargetRegressor\n",
        "\n",
        "from scipy.special import softmax\n",
        "\n",
        "\n",
        "class SimpleTransformerClassificationEstimator(BaseEstimator):\n",
        "  def __init__(self, model_maker, avoid_masking=False, dev_size=0.2, extra_metrics={}):\n",
        "    self.model_maker = model_maker\n",
        "    self.avoid_masking = avoid_masking\n",
        "    self.dev_size = dev_size\n",
        "    self.extra_metrics = extra_metrics\n",
        "\n",
        "    self.model_ = None\n",
        "    self.classes_ = None\n",
        "\n",
        "  def fit(self, X, y):\n",
        "    train_df = pd.DataFrame({\"text\": X, \"target\": y})[[\"text\", \"target\"]]\n",
        "    self.model_ = self.model_maker()\n",
        "    if self.avoid_masking:\n",
        "      train_df.text = train_df.text.apply(hack_to_avoid_masking, tokenizer=self.model_.tokenizer,)\n",
        "    \n",
        "    st_eval_df = None\n",
        "    if self.model_.args.get('use_early_stopping'):\n",
        "      print(f\"using early stopping\")\n",
        "      train_df, st_eval_df = train_test_split(train_df, test_size=self.dev_size, stratify=train_df[\"target\"])\n",
        "      train_baserate_acc = max(train_df.target.mean(), 1.-train_df.target.mean())\n",
        "      eval_baserate_acc = max(st_eval_df.target.mean(), 1.-st_eval_df.target.mean())\n",
        "      print(f\"using\\n\\ttrain_df: {train_df.shape}, baserate {train_baserate_acc:.3f}\\n\\tst_eval_df: {st_eval_df.shape}, baserate {eval_baserate_acc:.3f}\")\n",
        "    \n",
        "    if self.model_.args.get(\"multi_label\"):\n",
        "      train_df[\"target\"] = [[t] for t in train_df[\"target\"]]\n",
        "      print(f\"using multi_label for train_df\")\n",
        "      display(train_df.head())\n",
        "      if st_eval_df is not None:\n",
        "        st_eval_df[\"target\"] = [[t] for t in st_eval_df[\"target\"]]\n",
        "        print(f\"using multi_label for st_eval_df\")\n",
        "        display(st_eval_df.head())\n",
        "\n",
        "    self.model_.train_model(train_df, eval_df=st_eval_df, **self.extra_metrics)\n",
        "    if self.model_.args.get('use_early_stopping'):\n",
        "      # load best model\n",
        "      best_model_dir = self.model_.args.get('best_model_dir')\n",
        "      model_type = self.model_.args[\"model_type\"] \n",
        "      kwargs = {\"use_cuda\": True, \"num_labels\": 1 if self.model_.args.get(\"multi_label\") else 2}\n",
        "\n",
        "      del self.model_\n",
        "      torch.cuda.empty_cache()\n",
        "      self.model_ = ClassificationModel(model_type, best_model_dir, **kwargs)\n",
        "\n",
        "    self.classes_ = [0, 1]\n",
        "    return self\n",
        "\n",
        "  def predict(self, X_):\n",
        "    if self.avoid_masking:\n",
        "      X = [hack_to_avoid_masking(t, self.model_.tokenizer,) for t in X_]\n",
        "    else:\n",
        "      X = X_\n",
        "    preds, logits = self.model_.predict(X)\n",
        "    return preds\n",
        "\n",
        "  def predict_proba(self, X_):\n",
        "    if self.avoid_masking:\n",
        "      X = [hack_to_avoid_masking(t, self.model_.tokenizer,) for t in X_]\n",
        "    else:\n",
        "      X = X_\n",
        "    preds, logits = self.model_.predict(X)\n",
        "    if self.model_.args['sliding_window']:\n",
        "      logits = [np.mean(l, axis=0) for l in logits]\n",
        "    if self.model_.args.get(\"multi_label\"):\n",
        "      proba = logits\n",
        "    else:\n",
        "      proba = softmax(logits, axis=1)\n",
        "    return proba"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AV-1N9VOg2lk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import mean_squared_error, r2_score, explained_variance_score, mean_gamma_deviance, make_scorer\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, precision_recall_curve, log_loss, matthews_corrcoef\n",
        "from sklearn.metrics import average_precision_score, brier_score_loss, hinge_loss\n",
        "\n",
        "from scipy.stats import spearmanr\n",
        "\n",
        "def spearman_score(y_true, y_pred):\n",
        "  return spearmanr(y_true, y_pred)[0]\n",
        "\n",
        "scoring = [\"neg_brier_score\", \"average_precision\", \"accuracy\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ym1otCrxO5IW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "baserate_brier = -1*brier_score_loss(model_inputs.target, [model_inputs.target.mean() for _ in range(len(model_inputs.target))])\n",
        "\n",
        "print(f\"baserate_loss (all): {baserate_loss(model_inputs.target):.3f}\")\n",
        "print(f\"baserate_brier (all): {baserate_brier:.3f}\")\n",
        "print(f\"baserate_acc (all): {max(model_inputs.target.mean(), 1.-model_inputs.target.mean()):.3f}\")\n",
        "print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJIvEQMmSyvO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import TimeSeriesSplit, StratifiedKFold\n",
        "tss = TimeSeriesSplit(n_splits=4)\n",
        "\n",
        "_custom_tss = list(tss.split(model_inputs.target.values))[3:]\n",
        "custom_tss = [(train_index, _custom_tss[-1][1]) \n",
        "              for outer_train_index, _ in _custom_tss\n",
        "              for train_index, __ in StratifiedKFold(n_splits=4, shuffle=True).split(outer_train_index, model_inputs.target.values[outer_train_index])\n",
        "              ]\n",
        "\n",
        "for train_index, test_index in custom_tss:\n",
        "  print(f\"TRAIN {train_index.min()} to {train_index.max()}: \\t{model_inputs.target.values[train_index].mean():.2f}\")\n",
        "  print(f\"TRAIN\\tsize {len(train_index)}\")\n",
        "  print(f\"TEST  {test_index.min()} to {test_index.max()}: \\t{model_inputs.target.values[test_index].mean():.2f}\")\n",
        "  print(f\"TEST\\tsize {len(test_index)}\")\n",
        "  print()\n",
        "\n",
        "print(f\"ALL: \\t\\t\\t{model_inputs.target.values.mean():.2f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-uSPzlQvtea",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import logging\n",
        "logging.basicConfig(level=logging.INFO)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLFWBT-MK4kb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# if you want to cross-validate\n",
        "do_cv = False\n",
        "use_tss_with_cv = False\n",
        "score_cv_multimetric=True\n",
        "\n",
        "if do_cv:\n",
        "  torch.cuda.empty_cache()\n",
        "  \n",
        "  wrapped = SimpleTransformerClassificationEstimator(model_maker=lambda overrides=None:make_bert(\"bert_cv\", bert_config=BERT_CONFIG_EXP, add_timestamp=True, regression=False,\n",
        "                                                                                                   overrides=overrides))\n",
        "\n",
        "  cv_results = cross_validate(wrapped, \n",
        "                              X=model_inputs.text.values, \n",
        "                              y=model_inputs.target.values,\n",
        "                              scoring=scoring if score_cv_multimetric else [\"accuracy\"], \n",
        "                              cv=tss if use_tss_with_cv else 4, \n",
        "                              return_train_score=True)\n",
        "  \n",
        "  print(cv_results)\n",
        "  print('mean')\n",
        "  display(pd.DataFrame(cv_results).mean().sort_index())\n",
        "  print('std')\n",
        "  display(pd.DataFrame(cv_results).std().sort_index())\n",
        "\n",
        "  !rm -r bert_cv*"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yl3wF8RF0Jq3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "display(pd.DataFrame(cv_results).std().sort_index())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8RS80koJ6RWM",
        "colab_type": "text"
      },
      "source": [
        "Fit and save"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p95NMTxt4RQU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final_fit_name = \"\"  # fill in\n",
        "DEV_SIZE=0.2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kbbt8NkX6SoF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.cuda.empty_cache()\n",
        "! rm -r cache_dir/*\n",
        "\n",
        "wrapped = SimpleTransformerClassificationEstimator(model_maker=lambda:make_bert(final_fit_name, bert_config=BERT_CONFIG_EXP, \n",
        "                                                                                add_timestamp=False, regression=False),\n",
        "                                                    dev_size=DEV_SIZE)\n",
        "  \n",
        "wrapped.fit(model_inputs.text.values, model_inputs.target.values)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZlpHHk4Iht_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for verifying the model works locally -- try on some examples you have saved in a pickle file\n",
        "import pickle\n",
        "from textwrap import wrap\n",
        "\n",
        "with open(\"reward/textpost_examples.pkl.gz\", \"rb\") as f:\n",
        "  textpost_examples = pickle.load(f)\n",
        "textpost_examples = [s.lstrip(\"ç¿°\") for s in textpost_examples]\n",
        "\n",
        "proba_tpe = wrapped.predict_proba(textpost_examples)[:, 1]\n",
        "\n",
        "\n",
        "def show_note_probas(texts, probas):\n",
        "  for tpe, proba in zip(texts, probas):\n",
        "    print(f\"\\tpredicted prob: {proba:.1%}\\n\")\n",
        "    print(\"\\n~_~_~_~_~_\\n\")\n",
        "    print(\"\\n\".join(wrap(tpe)))\n",
        "    print(\"\\n~_~_~_~_~_\\n\")\n",
        "\n",
        "show_note_probas(textpost_examples, proba_tpe)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sn_RSEGkKgr1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# can't remember if this is needed -- i think it was at one point\n",
        "if not os.path.exists(final_fit_name):\n",
        "  os.mkdir(final_fit_name)\n",
        "\n",
        "model_to_save = wrapped.model_.model.module if hasattr(wrapped.model_.model, \"module\") else wrapped.model_.model\n",
        "model_to_save.save_pretrained(final_fit_name)\n",
        "wrapped.model_.tokenizer.save_pretrained(final_fit_name)\n",
        "torch.save(wrapped.model_.args, os.path.join(final_fit_name, \"training_args.bin\"))\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}